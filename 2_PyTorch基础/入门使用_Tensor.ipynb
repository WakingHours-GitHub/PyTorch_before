{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab4c0eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'1.10.2+cu113'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "396a70cd",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "张量是一个统称，其中包含很多类型：是一个可以包含高维数据的统称的一个数据结构（类型）\n",
    "\n",
    "1. 0阶张量：标量, scaler、常数，0-D Tensor . 在计算loss中, 返回的就是一个标量.\n",
    "\n",
    "2. 1阶张量：向量 vector，1-D Tensor \n",
    "\n",
    "3. 2阶张量：矩阵 matrix，2-D Tensor\n",
    "\n",
    "4. 3阶张量\n",
    "\n",
    "5. ...\n",
    "\n",
    "6. N阶张量\n",
    "\n",
    "   这个阶也称之为维度, 即shape个数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d581216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在python中创建Tensor\n",
    "# 首先要区分的是torch.Tensor() 和 torch.tensor()\n",
    "# 首先大写的Tensoe是类, 一般来说是传入形状然后生成未初始化的tensor. 我们可以通过类直接创建不同类型的tensor\n",
    "# 而小的的tensor是方法, 一般来说是传入数据, 直接生成tensor. 我们可以指定dtype来控制数据类型\n",
    "# 接下来我们就使用torch中的方法创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 3],\n        [1, 4]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用python中的list创建tensor\n",
    "t1 = torch.tensor([[1, 3], [1, 4]])\n",
    "t1.dtype # torch.int64\n",
    "t1\n",
    "# tensor([[1, 3],\n",
    "        # [1, 4]])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18330837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3.],\n        [4., 5., 6.]], dtype=torch.float64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  使用数据直接创建tensor\n",
    "torch.tensor(np.array(\n",
    "    [[1, 2, 3],  \n",
    "     [4, 5, 6]],\n",
    "     dtype=np.float64 # 在np中指定dtype类型\n",
    ")) # 那么生成的tensor类型也是与np类型相同的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12404482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n        [0.0000e+00, 1.1210e-44, 0.0000e+00]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Torch的API创建tensor：\n",
    "# 1. 创建一个空的tenosr变量, 未初始化, 会用无用数据进行填充\n",
    "torch.empty([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2489bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全为1 的tensor\n",
    "torch.ones([4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ab0413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全为0的tensor\n",
    "torch.zeros([4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12d5646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10],\n        [10, 10, 10, 10, 10]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定数值创建:\n",
    "# 例子: 创建一个4*5的矩阵, 并全部用10进行填充\n",
    "torch.full([4 ,5],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3831343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5.4564, 9.3058, 5.7780],\n        [7.3136, 7.3910, 5.1064],\n        [5.5680, 5.5340, 8.8255],\n        [5.7724, 5.4930, 9.5683]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机创建_创建一个矩阵, 符合均匀分布, 范围: [0, 1)\n",
    "torch.rand(size=(4, 3))\n",
    "# 如果要创建到固定范围内: [a, b)\n",
    "a = 5\n",
    "b = 10\n",
    "\n",
    "(b-a) * torch.rand(size=(4, 3)) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[9, 8, 9, 9, 9, 8],\n        [9, 3, 6, 7, 6, 9],\n        [9, 3, 7, 6, 4, 9],\n        [7, 9, 8, 7, 8, 7]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建随机整数:\n",
    "# 创建整数, 同样符合均匀分布\n",
    "torch.randint(low=3, high=10, size=(4, 6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.3156, -0.4003,  1.3474],\n        [ 1.2182, -0.3865,  0.8569],\n        [-0.8072,  1.0584,  1.5826],\n        [ 1.2820, -0.0606,  0.7341]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建随机tensor, 符合标准正态分布:\n",
    "torch.randn(size=(4, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[13.9482],\n        [ 4.2463],\n        [ 9.1501],\n        [ 9.3327],\n        [ 6.6901],\n        [11.3228],\n        [ 8.5560],\n        [10.1490],\n        [15.0447],\n        [11.6420]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以让每个元素, 都服从不同的正太分布:\n",
    "torch.normal(\n",
    "    mean=torch.full(size=(10, 1), fill_value=10.),\n",
    "    std=torch.full(size=(10,1), fill_value=4.0)\n",
    ")\n",
    "# 注意, 必须是类型是一样的,并且大小也要是一样的.\n",
    "# 可以都指定为Float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tensor的常用方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当tensor中只有一个元素的时候, 我们可以直接使用该方法获取其中的元素值\n",
    "# 不用在一层一层索引了\n",
    "t2 = torch.tensor([[1]], dtype=torch.float32)\n",
    "t2 # 此时如果我们需要取出里面的值我们需要一层一层索引:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但是我们可以直接使用: item()就直接可以得到其中的元素值\n",
    "t2.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.1523, -1.6463, -1.0331, -0.8791],\n        [-1.9095, -2.6722,  1.7284, -0.8762],\n        [ 0.2697,  0.4617, -0.1400,  0.5709]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为numpy数组\n",
    "t3 = torch.randn(size=(3, 4))\n",
    "t3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3.numpy(): [[ 1.152254   -1.6463319  -1.0331253  -0.87907887]\n",
      " [-1.909497   -2.6722298   1.728365   -0.8762252 ]\n",
      " [ 0.26970991  0.46171832 -0.14001462  0.5709199 ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"t3.numpy():\",t3.numpy()) # 直接从tensor 转换到 ndarray\n",
    "print(type(t3.numpy())) # 直接就是原地修改了。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 20])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取形状\n",
    "t4 = torch.Tensor(size=(10, 20))\n",
    "t4.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}